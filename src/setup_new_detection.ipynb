{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992d249e-69f3-4423-9f54-b7dcc2a06568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from sklearn.preprocessing import Normalizer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cbb776c-6bf0-4e90-bcc2-5d4dcbe1cc61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_angles = angles / 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dafcbd-3f1f-49be-a996-89d4e569b7f3",
   "metadata": {},
   "source": [
    "# extract from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a796ba66-a759-4d39-8479-52ccd6e93542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "1\n",
      "9\n",
      "1\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "4\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "1\n",
      "4\n",
      "6\n",
      "5\n",
      "#######\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('/home/me/Programmierung/AI_Test/find_arrow_symbol/detect_arrow/50_cm.jpg')\n",
    "blurred = cv2.blur(img, (3,3))\n",
    "gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "retval, bw_img = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "cnts, _ = cv2.findContours(bw_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  # arrow seems to be internal\n",
    "\n",
    "point_list = []\n",
    "\n",
    "for num, contour in enumerate(cnts):\n",
    "    M = cv2.moments(contour)\n",
    "    if (M[\"m00\"] != 0):\n",
    "        x_c = int(M[\"m10\"] / M[\"m00\"])\n",
    "        y_c = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        x_c = -1\n",
    "        y_c = -1\n",
    "    retval = cv2.arcLength(contour, True)\n",
    "    points = cv2.approxPolyDP(contour, 0.04 * retval, True)\n",
    "    print(len(points))\n",
    "    if len(points) == 5:\n",
    "        point_list.append(points.reshape((5,2)))\n",
    "        \n",
    "    #return (points, x_c, y_c)\n",
    "print('#######')\n",
    "print(len(point_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b668c1a3-08e0-4fd4-89b0-4d16835ca215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for num in range(len(point_list)):\n",
    "    if len(point_list[num]) == 5:\n",
    "        img2 = np.zeros((480, 640,3))\n",
    "        cv2.drawContours(img2, cnts, num, (0,0,255), thickness=10)\n",
    "        #cv2.imshow('orig', img)\n",
    "        cv2.imshow('test', img2)\n",
    "        cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6e5b9f58-2738-48ff-af1c-f8fe965905df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array(point_list)\n",
    "np.save('test', arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23381b92-22c0-4e86-8105-2596f3d2f2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr2 = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bfeb5b90-7739-48fa-a16d-7ae7d011ff31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ee41486-cebf-43c3-aa38-9ad847fd2116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b00f9a-39f1-4d9d-912b-3ec50146847a",
   "metadata": {},
   "source": [
    "# extract from video for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ee939c-014a-4246-9433-e962304441eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_path = '/home/me/Videos/Kamera/2023-09-01-163208.webm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4898d8ff-b605-4886-a10b-d89ec33c6b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_good_values(frame):\n",
    "    blurred = cv2.blur(frame, (3,3))\n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "    retval, bw_img = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    \n",
    "    cnts, _ = cv2.findContours(bw_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    point_list = []\n",
    "    \n",
    "    for num, contour in enumerate(cnts):\n",
    "        #print(contour)\n",
    "        M = cv2.moments(contour)\n",
    "        if (M[\"m00\"] != 0):\n",
    "            x_c = int(M[\"m10\"] / M[\"m00\"])\n",
    "            y_c = int(M[\"m01\"] / M[\"m00\"])\n",
    "        else:\n",
    "            x_c = -1\n",
    "            y_c = -1\n",
    "        retval = cv2.arcLength(contour, True)\n",
    "        points = cv2.approxPolyDP(contour, 0.04 * retval, True)\n",
    "        if len(points) == 5:\n",
    "            point_list.append(points.reshape((5,2)))\n",
    "\n",
    "        \n",
    "    return point_list\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "800c3593-eaa2-42b6-96cd-71837a8d3258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "found_shapes_raw = []\n",
    "wrong_shapes_raw = []\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    cap.release()\n",
    "    raise SystemExit()\n",
    "    \n",
    "frameRate = cap.get(5) #frame rate\n",
    "abort = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    " \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame',frame)\n",
    " \n",
    "        key = cv2.waitKey(25) & 0xFF\n",
    "    \n",
    "        # Press Q on keyboard to  exit\n",
    "        if key == ord('q') or abort:\n",
    "            break\n",
    "        elif frameId % np.floor(frameRate) == 0:\n",
    "            try:\n",
    "                values = extract_good_values(frame)\n",
    "            except:\n",
    "                print('an error occurred')\n",
    "                raise SystemExit()\n",
    "                \n",
    "            for num, features in enumerate(values):\n",
    "                con_frame = frame.copy()\n",
    "                cv2.drawContours(con_frame, values, num, (0,0,255), thickness=10)\n",
    "                cv2.imshow('Frame',con_frame)\n",
    "                key = cv2.waitKey(0) & 0xFF\n",
    "                if key == ord('n'):\n",
    "                    wrong_shapes_raw.append(features)\n",
    "                elif key == ord('y'):\n",
    "                    found_shapes_raw.append(features)\n",
    "                elif key == ord('q'):\n",
    "                    abort = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "    # Break the loop\n",
    "    else: \n",
    "        break\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "good_values = np.array(found_shapes_raw)\n",
    "bad_values = np.array(wrong_shapes_raw)\n",
    "np.save('good_values', good_values)\n",
    "np.save('bad_values', bad_values)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0687c61e-954b-4aa5-af42-8d850bf9665c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e9a5bd-dfb6-40ef-bca8-0cc3eb31fe3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a28ddd-f716-4e96-a872-19f37e92a004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_good_values = np.load('good_values.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ae3828-6765-486b-aee6-afb7537c1aad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 5, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_good_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70efd8-8998-441c-b5fe-889de43786b6",
   "metadata": {},
   "source": [
    "# minAreaRect, transform, scaling, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6454e19d-8e2d-49fe-9dae-1c3e1eb1037f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get better shape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1b0a44d-63ce-4c5b-9ad8-dec43f5a20ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape_reference = np.load('shape_reference.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8981b93a-e498-42b5-8331-190dce067b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = cv2.moments(shape_reference)\n",
    "x_c = int(M[\"m10\"] / M[\"m00\"])\n",
    "y_c = int(M[\"m01\"] / M[\"m00\"])\n",
    "retval = cv2.arcLength(shape_reference, True)\n",
    "points = cv2.approxPolyDP(shape_reference, 0.04 * retval, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d999c7da-0132-4016-9d71-7e15394a84a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('shape_reference_points', points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0643ed5b-e18a-45b9-aabd-cf2e991709d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "points = np.load('shape_reference_points.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c3b8f2-c183-4840-8545-decff51d6ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_rect = cv2.minAreaRect(points)\n",
    "# x,y,w,h = cv.boundingRect(cnt)\n",
    "# center (x,y), (width, height), angle of rotation ( 90 degree is up), negative values possible\n",
    "# center (x,y), (width, height), angle of rotation ( 90 degree is up), negative values possible\n",
    "ref_box = cv2.boxPoints(reference_rect)\n",
    "ref_box = np.intp(ref_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db25d74a-6695-40de-963c-737c00654863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((291.92498779296875, 218.60198974609375),\n",
       " (135.26010131835938, 409.2398376464844),\n",
       " 6.668918609619141)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "839b493e-4b7f-4fc5-b782-163f1b9da5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "black = np.zeros((480, 640, 4))\n",
    "cv2.drawContours(black, points, -1, (255, 0, 0), thickness=10)\n",
    "cv2.drawContours(black, [ref_box], -1, (0, 0, 255), thickness=5)\n",
    "cv2.imshow('shape_reference', black)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7850de4-3e67-46c8-bd31-ae07903aa4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('shape_reference_width_and_height', reference_rect[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ba5d967-1821-4dc3-9874-3b73f7520cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_width, ref_height = np.load('shape_reference_width_and_height.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "944b1b26-d4d5-43db-80ab-ece888d9871a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.26010131835938"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a68e61a-9e23-40d7-a9fa-ee1bbeac9b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409.2398376464844"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058b7bc-c4c7-4de7-bc33-2f78c20ccda2",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48691f96-72d4-428b-b5fc-e0db2471f6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from sklearn.preprocessing import Normalizer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1844109c-e337-4bbe-8dfe-73b7c15e66ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_good_values = np.load('good_values.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a535c4c-503f-46f8-b1a1-986b9d81e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_raw_features = loaded_good_values[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c9bbe99-2f03-42f2-a1ce-6cd1c6725817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[266, 139],\n",
       "       [322, 135],\n",
       "       [386, 361],\n",
       "       [339, 451],\n",
       "       [269, 380]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_raw_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cffbcadc-7dee-4072-982e-700b11134e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((326.535888671875, 293.0493469238281),\n",
       " (316.1871337890625, 117.22742462158203),\n",
       " 89.28681945800781)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_rect = cv2.minAreaRect(good_raw_features)\n",
    "# center (x,y), (width, height), angle of rotation ( 90 degree is up, clockwise), negative values possible\n",
    "min_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f9b2ab7-bdfc-4edf-a7a8-01c25271ca11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "box = cv2.boxPoints(min_rect)\n",
    "box = np.intp(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "983c596f-1eec-45c9-a1ba-0214ab6b5b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_rect = (*min_rect[:2], 45)\n",
    "box = cv2.boxPoints(test_rect)\n",
    "box = np.intp(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50dd8c98-77fe-4d0f-9db2-d822757da909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "black = np.zeros((480, 640, 4))\n",
    "cv2.drawContours(black, [good_raw_features], -1, (255, 0, 0), thickness=5)\n",
    "cv2.drawContours(black,[box],0,(0,0,255),2)\n",
    "cv2.imshow('example', black)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d54b564a-a405-46d2-9d7d-f3970f70e97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rot_point(min_rect):\n",
    "    width_to_height = min_rect[1][0] / min_rect[0][0]\n",
    "    \n",
    "    box = cv2.boxPoints(test_rect)\n",
    "    box = np.intp(box)\n",
    "    \n",
    "    lowest_point= np.arry((0, 1_000_000))\n",
    "    second_lowest_point = np.arry((0, 2_000_000))\n",
    "    for i in range(len(box)):\n",
    "        if box[i][1] < lowest_point[1]:\n",
    "            lowest_point = box[i]\n",
    "        elif box[i][1] < second_lowest_point[1]:\n",
    "            second_lowest_point = box[i]\n",
    "        \n",
    "    if widht_to_height > 0:\n",
    "        if 0 <= min_rect[2] < 90:\n",
    "            # lowest point, rot further\n",
    "            offset_point = lowest_point\n",
    "            needed_rot = 90 - min_rect[2]\n",
    "        else:\n",
    "            # second lowest point, rot back\n",
    "            offset_point = second_lowest_point\n",
    "            needed_rot = 90 - min_rect[2]\n",
    "            \n",
    "    else:\n",
    "        if 0 < min_rect[2] <= 90:\n",
    "            # second lowest point, rot back\n",
    "            offset_point = second_lowest_point\n",
    "            needed_rot = -min_rect[2]\n",
    "            \n",
    "        else:\n",
    "            # lowest point, rot further\n",
    "            offset_point = lowest_point\n",
    "            needed_rot = 180 - min_rect[2]\n",
    "            \n",
    "    return offset_point, needed_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a1026cc-a64f-4f1d-aeaf-dc816d698794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73213e76-3481-4ff9-885f-a00f188ba349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a09dffd-803f-42dd-88ea-70c11733921d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05319779-6b72-493a-91c2-469879c762cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd482a56-17f4-48b6-861f-a2d861e7c288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f57096-8df8-4689-94a0-bf9a6a470cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a9ce8-55be-4691-abad-434b918e6ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3633634-91b8-4ebe-98d8-82693088de1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[265, 135],\n",
       "       [383, 134],\n",
       "       [387, 450],\n",
       "       [269, 451]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868add1-3199-4219-93f9-3dc9f2e6b2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d60392-e671-411c-8561-1d836e9f6317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18183bc2-aaaa-4092-a3b0-25be89fdd283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b1cc4-8f12-4edf-b881-9da0229c0185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b00e1-5bec-4d1f-92fc-ca257435612c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ebdced-6c6a-4c08-8e53-45403197b393",
   "metadata": {},
   "source": [
    "# svm opencv (svm.save for saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "566bddc6-d224-4908-9274-23b2be8dd3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "# Set up training data\n",
    "labels = np.array([1, -1, -1, -1])\n",
    "trainingData = np.matrix([[501, 10], [255, 10], [501, 255], [10, 501]], dtype=np.float32)\n",
    "# Train the SVM\n",
    "svm = cv.ml.SVM_create()\n",
    "svm.setType(cv.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\n",
    "svm.setTermCriteria((cv.TERM_CRITERIA_MAX_ITER, 100, 1e-6))\n",
    "svm.train(trainingData, cv.ml.ROW_SAMPLE, labels)\n",
    "# Data for visual representation\n",
    "width = 512\n",
    "height = 512\n",
    "image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# Show the decision regions given by the SVM\n",
    "green = (0,255,0)\n",
    "blue = (255,0,0)\n",
    "for i in range(image.shape[0]):\n",
    "    for j in range(image.shape[1]):\n",
    "        sampleMat = np.matrix([[j,i]], dtype=np.float32)\n",
    "        response = svm.predict(sampleMat)[1]\n",
    "        response = response[0][0]\n",
    "        \n",
    "        if response == 1:\n",
    "            image[i,j] = green\n",
    "        elif response == -1:\n",
    "            image[i,j] = blue\n",
    "        else:\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        \n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "        \n",
    "# Show the training data\n",
    "thickness = -1\n",
    "cv.circle(image, (501, 10), 5, ( 0, 0, 0), thickness)\n",
    "cv.circle(image, (255, 10), 5, (255, 255, 255), thickness)\n",
    "cv.circle(image, (501, 255), 5, (255, 255, 255), thickness)\n",
    "cv.circle(image, ( 10, 501), 5, (255, 255, 255), thickness)\n",
    "# Show support vectors\n",
    "thickness = 2\n",
    "sv = svm.getUncompressedSupportVectors()\n",
    "for i in range(sv.shape[0]):\n",
    "    cv.circle(image, (int(sv[i,0]), int(sv[i,1])), 6, (128, 128, 128), thickness)\n",
    "    \n",
    "\n",
    "#cv.imwrite('result.png', image) # save the image\n",
    "cv.imshow('SVM Simple Example', image) # show it to the user\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18f3267a-66ae-482e-89c4-6f68898b6c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6645e-abd3-4771-8033-a5b82bb00595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
