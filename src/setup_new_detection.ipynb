{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992d249e-69f3-4423-9f54-b7dcc2a06568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from sklearn.preprocessing import Normalizer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cbb776c-6bf0-4e90-bcc2-5d4dcbe1cc61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_angles = angles / 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dafcbd-3f1f-49be-a996-89d4e569b7f3",
   "metadata": {},
   "source": [
    "# extract from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a796ba66-a759-4d39-8479-52ccd6e93542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "1\n",
      "9\n",
      "1\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "4\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "1\n",
      "4\n",
      "6\n",
      "5\n",
      "#######\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('/home/me/Programmierung/AI_Test/find_arrow_symbol/detect_arrow/50_cm.jpg')\n",
    "blurred = cv2.blur(img, (3,3))\n",
    "gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "retval, bw_img = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "cnts, _ = cv2.findContours(bw_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  # arrow seems to be internal\n",
    "\n",
    "point_list = []\n",
    "\n",
    "for num, contour in enumerate(cnts):\n",
    "    M = cv2.moments(contour)\n",
    "    if (M[\"m00\"] != 0):\n",
    "        x_c = int(M[\"m10\"] / M[\"m00\"])\n",
    "        y_c = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        x_c = -1\n",
    "        y_c = -1\n",
    "    retval = cv2.arcLength(contour, True)\n",
    "    points = cv2.approxPolyDP(contour, 0.04 * retval, True)\n",
    "    print(len(points))\n",
    "    if len(points) == 5:\n",
    "        point_list.append(points.reshape((5,2)))\n",
    "        \n",
    "    #return (points, x_c, y_c)\n",
    "print('#######')\n",
    "print(len(point_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b668c1a3-08e0-4fd4-89b0-4d16835ca215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for num in range(len(point_list)):\n",
    "    if len(point_list[num]) == 5:\n",
    "        img2 = np.zeros((480, 640,3))\n",
    "        cv2.drawContours(img2, cnts, num, (0,0,255), thickness=10)\n",
    "        #cv2.imshow('orig', img)\n",
    "        cv2.imshow('test', img2)\n",
    "        cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6e5b9f58-2738-48ff-af1c-f8fe965905df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array(point_list)\n",
    "np.save('test', arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23381b92-22c0-4e86-8105-2596f3d2f2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr2 = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bfeb5b90-7739-48fa-a16d-7ae7d011ff31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ee41486-cebf-43c3-aa38-9ad847fd2116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b00f9a-39f1-4d9d-912b-3ec50146847a",
   "metadata": {},
   "source": [
    "# extract from video for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ee939c-014a-4246-9433-e962304441eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_path = '/home/me/Videos/Kamera/2023-09-01-163208.webm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4898d8ff-b605-4886-a10b-d89ec33c6b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_good_values(frame):\n",
    "    blurred = cv2.blur(frame, (3,3))\n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "    retval, bw_img = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    \n",
    "    cnts, _ = cv2.findContours(bw_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    point_list = []\n",
    "    \n",
    "    for num, contour in enumerate(cnts):\n",
    "        #print(contour)\n",
    "        M = cv2.moments(contour)\n",
    "        if (M[\"m00\"] != 0):\n",
    "            x_c = int(M[\"m10\"] / M[\"m00\"])\n",
    "            y_c = int(M[\"m01\"] / M[\"m00\"])\n",
    "        else:\n",
    "            x_c = -1\n",
    "            y_c = -1\n",
    "        retval = cv2.arcLength(contour, True)\n",
    "        points = cv2.approxPolyDP(contour, 0.04 * retval, True)\n",
    "        if len(points) == 5:\n",
    "            point_list.append(points.reshape((5,2)))\n",
    "\n",
    "        \n",
    "    return point_list\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "800c3593-eaa2-42b6-96cd-71837a8d3258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "found_shapes_raw = []\n",
    "wrong_shapes_raw = []\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    cap.release()\n",
    "    raise SystemExit()\n",
    "    \n",
    "frameRate = cap.get(5) #frame rate\n",
    "abort = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    " \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame',frame)\n",
    " \n",
    "        key = cv2.waitKey(25) & 0xFF\n",
    "    \n",
    "        # Press Q on keyboard to  exit\n",
    "        if key == ord('q') or abort:\n",
    "            break\n",
    "        elif frameId % np.floor(frameRate) == 0:\n",
    "            try:\n",
    "                values = extract_good_values(frame)\n",
    "            except:\n",
    "                print('an error occurred')\n",
    "                raise SystemExit()\n",
    "                \n",
    "            for num, features in enumerate(values):\n",
    "                con_frame = frame.copy()\n",
    "                cv2.drawContours(con_frame, values, num, (0,0,255), thickness=10)\n",
    "                cv2.imshow('Frame',con_frame)\n",
    "                key = cv2.waitKey(0) & 0xFF\n",
    "                if key == ord('n'):\n",
    "                    wrong_shapes_raw.append(features)\n",
    "                elif key == ord('y'):\n",
    "                    found_shapes_raw.append(features)\n",
    "                elif key == ord('q'):\n",
    "                    abort = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "    # Break the loop\n",
    "    else: \n",
    "        break\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "good_values = np.array(found_shapes_raw)\n",
    "bad_values = np.array(wrong_shapes_raw)\n",
    "np.save('good_values', good_values)\n",
    "np.save('bad_values', bad_values)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0687c61e-954b-4aa5-af42-8d850bf9665c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e9a5bd-dfb6-40ef-bca8-0cc3eb31fe3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a28ddd-f716-4e96-a872-19f37e92a004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_good_values = np.load('good_values.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ae3828-6765-486b-aee6-afb7537c1aad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 5, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_good_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70efd8-8998-441c-b5fe-889de43786b6",
   "metadata": {},
   "source": [
    "# minAreaRect, transform, scaling, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a535c4c-503f-46f8-b1a1-986b9d81e6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bbe99-2f03-42f2-a1ce-6cd1c6725817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbcadc-7dee-4072-982e-700b11134e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648d38c-939f-4a87-bfb9-ea985e4f3891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ebdced-6c6a-4c08-8e53-45403197b393",
   "metadata": {},
   "source": [
    "# svm opencv (svm.save for saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "566bddc6-d224-4908-9274-23b2be8dd3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "# Set up training data\n",
    "labels = np.array([1, -1, -1, -1])\n",
    "trainingData = np.matrix([[501, 10], [255, 10], [501, 255], [10, 501]], dtype=np.float32)\n",
    "# Train the SVM\n",
    "svm = cv.ml.SVM_create()\n",
    "svm.setType(cv.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\n",
    "svm.setTermCriteria((cv.TERM_CRITERIA_MAX_ITER, 100, 1e-6))\n",
    "svm.train(trainingData, cv.ml.ROW_SAMPLE, labels)\n",
    "# Data for visual representation\n",
    "width = 512\n",
    "height = 512\n",
    "image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# Show the decision regions given by the SVM\n",
    "green = (0,255,0)\n",
    "blue = (255,0,0)\n",
    "for i in range(image.shape[0]):\n",
    "    for j in range(image.shape[1]):\n",
    "        sampleMat = np.matrix([[j,i]], dtype=np.float32)\n",
    "        response = svm.predict(sampleMat)[1]\n",
    "        response = response[0][0]\n",
    "        \n",
    "        if response == 1:\n",
    "            image[i,j] = green\n",
    "        elif response == -1:\n",
    "            image[i,j] = blue\n",
    "        else:\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        \n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "        \n",
    "# Show the training data\n",
    "thickness = -1\n",
    "cv.circle(image, (501, 10), 5, ( 0, 0, 0), thickness)\n",
    "cv.circle(image, (255, 10), 5, (255, 255, 255), thickness)\n",
    "cv.circle(image, (501, 255), 5, (255, 255, 255), thickness)\n",
    "cv.circle(image, ( 10, 501), 5, (255, 255, 255), thickness)\n",
    "# Show support vectors\n",
    "thickness = 2\n",
    "sv = svm.getUncompressedSupportVectors()\n",
    "for i in range(sv.shape[0]):\n",
    "    cv.circle(image, (int(sv[i,0]), int(sv[i,1])), 6, (128, 128, 128), thickness)\n",
    "    \n",
    "\n",
    "#cv.imwrite('result.png', image) # save the image\n",
    "cv.imshow('SVM Simple Example', image) # show it to the user\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18f3267a-66ae-482e-89c4-6f68898b6c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6645e-abd3-4771-8033-a5b82bb00595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
