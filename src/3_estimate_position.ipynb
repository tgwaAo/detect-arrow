{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62477dd7-95f6-4f82-b8bd-b6c76479daa4",
   "metadata": {},
   "source": [
    "# Estimate position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37f911-17cf-479c-914b-e9a22f77b536",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8803b184-df02-4ee5-a5eb-fdcae61e67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6018fd1-fe32-4ca1-9796-ea46a8a4bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_filename = '../reference.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9f95d0-54ce-4262-a91d-d0b2bb09f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@177.604] global loadsave.cpp:241 findDecoder imread_('../reference.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "ref_img = cv2.imread(reference_filename)\n",
    "if ref_img is not None:\n",
    "    plt.imshow(ref_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44a94ac-1b85-49da-b0aa-fb0b3173bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "if not 'model' in dir():\n",
    "    print('load model...')\n",
    "    from keras.models import load_model\n",
    "    model = load_model('arrow_detection.h5')\n",
    "    print('loaded model')\n",
    "    \n",
    "else:\n",
    "    print('model already loaded')\n",
    "    \n",
    "model.trainable = False\n",
    "\n",
    "COMPARED_SIZE = (24, 68)\n",
    "AREA_BORDER = COMPARED_SIZE[0] * COMPARED_SIZE[1]\n",
    "WIDTH_TO_HEIGHT = COMPARED_SIZE[0] / COMPARED_SIZE[1]\n",
    "SIZE_FACTOR = 0.3\n",
    "MIN_WIDTH_TO_HEIGHT = WIDTH_TO_HEIGHT * (1 - SIZE_FACTOR)\n",
    "MAX_WIDTH_TO_HEIGHT = WIDTH_TO_HEIGHT * (1 + SIZE_FACTOR)\n",
    "\n",
    "def prepare_rotation(min_rect):\n",
    "    \"\"\"\n",
    "    Prepare portrait rotation. No difference between up and down.\n",
    "    \"\"\"\n",
    "    \n",
    "    width_to_height = min_rect[1][0] / min_rect[1][1]\n",
    "    \n",
    "    if width_to_height >= 1:\n",
    "        return 90 - min_rect[2]\n",
    "    else:\n",
    "        return min_rect[2]\n",
    "\n",
    "def rotate_and_crop_min_rect(image, min_area_rect):\n",
    "    factor = 1.3\n",
    "\n",
    "    box = cv2.boxPoints(min_area_rect)\n",
    "    box = np.intp(box)\n",
    "\n",
    "    width = round(min_area_rect[1][0])\n",
    "    height = round(min_area_rect[1][1])\n",
    "\n",
    "    size_of_transformed_image = max(min_area_rect[1])\n",
    "    min_needed_height = int(np.sqrt(2 * np.power(size_of_transformed_image, 2)))\n",
    "\n",
    "    #angle = prepare_rotation(min_area_rect)\n",
    "    width_to_height = min_area_rect[1][0] / min_area_rect[1][1]\n",
    "    \n",
    "    if width_to_height >= 1:\n",
    "        angle = -1 * (90 - min_rect[2])\n",
    "    else:\n",
    "        angle = min_rect[2]    \n",
    "        \n",
    "    size = (min_needed_height, min_needed_height)\n",
    "\n",
    "    x_coordinates_of_box = box[:,0]\n",
    "    y_coordinates_of_box = box[:,1]\n",
    "    x_min = min(x_coordinates_of_box)\n",
    "    x_max = max(x_coordinates_of_box)\n",
    "    y_min = min(y_coordinates_of_box)\n",
    "    y_max = max(y_coordinates_of_box)\n",
    "\n",
    "    center = (int((x_min+x_max)/2), int((y_min+y_max)/2))\n",
    "    cropped = cv2.getRectSubPix(image, size, center) \n",
    "    M = cv2.getRotationMatrix2D((size[0]/2, size[1]/2), angle, 1.0)\n",
    "    cropped = cv2.warpAffine(cropped, M, size)\n",
    "    \n",
    "    if width_to_height >= 1:\n",
    "        cropped_rotated = cv2.getRectSubPix(cropped, (int(factor * height), int(factor * width)), (size[0]/2, size[1]/2))\n",
    "    else:\n",
    "        cropped_rotated = cv2.getRectSubPix(cropped, (int(factor * width), int(factor * height)), (size[0]/2, size[1]/2))\n",
    "\n",
    "    return cropped_rotated\n",
    "\n",
    "\n",
    "img = cv2.imread(img_filename)\n",
    "\n",
    "if img is None:\n",
    "    raise IOError('file not valid')\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.blur(gray_img, (3,3))\n",
    "\n",
    "sigma = 0.33\n",
    "# v = np.median(gray_img)\n",
    "v = np.median(blurred)\n",
    "\n",
    "#---- apply automatic Canny edge detection using the computed median----\n",
    "lower = int(max(0, (1.0 - sigma) * v))    #---- lower threshold\n",
    "upper = int(min(255, (1.0 + sigma) * v))  #---- upper threshold\n",
    "thresh_img = cv2.Canny(blurred, lower, upper)\n",
    "cnts, _ = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "filtered_list = []\n",
    "pos_filtered_to_pos_source = {}\n",
    "pos_filtered = 0\n",
    "for pos_source, con in enumerate(cnts):\n",
    "    min_rect = cv2.minAreaRect(con)\n",
    "    center, size, angle = min_rect\n",
    "    area = size[0] * size[1]\n",
    "\n",
    "    if area < AREA_BORDER:\n",
    "        continue\n",
    "\n",
    "    low_value = min(size[0], size[1])\n",
    "    high_value = max(size[0], size[1])\n",
    "    width_to_height = low_value / high_value\n",
    "\n",
    "    if MIN_WIDTH_TO_HEIGHT < width_to_height < MAX_WIDTH_TO_HEIGHT:\n",
    "        cropped_img = rotate_and_crop_min_rect(gray_img, min_rect)\n",
    "        small_img = cv2.resize(cropped_img, COMPARED_SIZE)\n",
    "        small_img = small_img / 255\n",
    "        filtered_list.append(small_img)\n",
    "        pos_filtered_to_pos_source[pos_filtered] = pos_source\n",
    "        pos_filtered += 1\n",
    "\n",
    "filtered_list = np.array(filtered_list)\n",
    "prediction = model.predict(filtered_list)\n",
    "print(prediction.shape)\n",
    "print(prediction)\n",
    "\n",
    "positive_contours = []\n",
    "negative_contours = []\n",
    "\n",
    "for pos, value in enumerate(prediction):\n",
    "    idx = pos_filtered_to_pos_source[pos]\n",
    "    if value[0] >= 0.5:\n",
    "        positive_contours.append(cnts[idx])\n",
    "    else:\n",
    "        negative_contours.append(cnts[idx])\n",
    "\n",
    "positive_contours = np.array(positive_contours, dtype=object)\n",
    "negative_contours = np.array(negative_contours, dtype=object)\n",
    "cv2.drawContours(img, positive_contours, -1, (0,0,255), 2)\n",
    "cv2.drawContours(img, negative_contours, -1, (255,0,0), 2)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9fd72-e8fb-45aa-98f4-2d60de2ea4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69d88e-b349-4b58-89bf-884bdf7a0be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0817a-923b-483b-9b84-05a02249824f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84daa81-66c1-4c3b-a225-464b70934ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb2eab-1f7e-48e0-af84-3513a64fbd23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce89f4-49c3-4331-93ee-e7a0c74033e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4e4ec-f17e-4de8-a28a-aee41005d5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3d229-ed3a-4957-8b55-e694b10190bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07455965-ed76-4bc6-a54d-9fbbc733fde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e4dd9-1a47-4eef-8700-19c580764c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
