{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c48ff6-19a2-413a-92e1-5c4f0a447e6f",
   "metadata": {},
   "source": [
    "# Use camera and estimate position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a926df-cbe4-4b73-901d-7992cae2b490",
   "metadata": {},
   "source": [
    "## Imports, definitions and loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fe64a7-f92f-4a44-a4b5-4c50790ef4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import threading\n",
    "from queue import Queue\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "171d0a2f-0f0d-44e6-89c0-24ff70ff6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.  118.]\n",
      " [  45.   61.]\n",
      " [ -45.   61.]\n",
      " [ -22. -118.]\n",
      " [  22. -118.]]\n",
      "-------------\n",
      "[[ -45.   61.]\n",
      " [ -22. -118.]\n",
      " [   0.  118.]\n",
      " [  22. -118.]\n",
      " [  45.   61.]]\n"
     ]
    }
   ],
   "source": [
    "points_printed = np.loadtxt('../coords_of_arrow.txt')\n",
    "print(points_printed)\n",
    "print('-------------')\n",
    "points_printed = points_printed[np.lexsort((points_printed[:,1], points_printed[:,0]))] # start with most left\n",
    "print(points_printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12cf282-c031-4e2c-8f0a-d783b621edf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[655.19135007,   0.        , 319.04529769],\n",
       "       [  0.        , 655.56447367, 223.19439802],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = np.loadtxt('../../cam-config/mtx.txt')\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96afc0aa-42a7-4c54-a49b-3bc6827f45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPARED_SIZE = (24, 68)\n",
    "AREA_BORDER = COMPARED_SIZE[0] * COMPARED_SIZE[1]\n",
    "WIDTH_TO_HEIGHT = COMPARED_SIZE[0] / COMPARED_SIZE[1]\n",
    "SIZE_FACTOR = 0.3\n",
    "MIN_WIDTH_TO_HEIGHT = WIDTH_TO_HEIGHT * (1 - SIZE_FACTOR)\n",
    "MAX_WIDTH_TO_HEIGHT = WIDTH_TO_HEIGHT * (1 + SIZE_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d267a8b-2177-4066-8965-65a8797d405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rotation(min_rect):\n",
    "    \"\"\"\n",
    "    Prepare portrait rotation. No difference between up and down.\n",
    "    \"\"\"\n",
    "    \n",
    "    width_to_height = min_rect[1][0] / min_rect[1][1]\n",
    "    \n",
    "    if width_to_height >= 1:\n",
    "        return 90 - min_rect[2]\n",
    "    else:\n",
    "        return min_rect[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d86154-34ee-4ddc-81ad-826f1c5a14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_crop(image, min_area_rect):\n",
    "    factor = 1.3\n",
    "\n",
    "    box = cv2.boxPoints(min_area_rect)\n",
    "    box = np.intp(box)\n",
    "\n",
    "    width = round(min_area_rect[1][0])\n",
    "    height = round(min_area_rect[1][1])\n",
    "\n",
    "    size_of_transformed_image = max(min_area_rect[1])\n",
    "    min_needed_height = int(np.sqrt(2 * np.power(size_of_transformed_image, 2)))\n",
    "\n",
    "    width_to_height = min_area_rect[1][0] / min_area_rect[1][1]\n",
    "    \n",
    "    if width_to_height >= 1:\n",
    "        angle = -1 * (90 - min_area_rect[2])\n",
    "    else:\n",
    "        angle = min_area_rect[2]    \n",
    "        \n",
    "    size = (min_needed_height, min_needed_height)\n",
    "\n",
    "    x_coordinates_of_box = box[:,0]\n",
    "    y_coordinates_of_box = box[:,1]\n",
    "    x_min = min(x_coordinates_of_box)\n",
    "    x_max = max(x_coordinates_of_box)\n",
    "    y_min = min(y_coordinates_of_box)\n",
    "    y_max = max(y_coordinates_of_box)\n",
    "\n",
    "    center = (int((x_min+x_max)/2), int((y_min+y_max)/2))\n",
    "    cropped = cv2.getRectSubPix(image, size, center) \n",
    "    M = cv2.getRotationMatrix2D((size[0]/2, size[1]/2), angle, 1.0)\n",
    "    cropped = cv2.warpAffine(cropped, M, size)\n",
    "    \n",
    "    if width_to_height >= 1:\n",
    "        cropped_rotated = cv2.getRectSubPix(cropped, (int(factor * height), int(factor * width)), (size[0]/2, size[1]/2))\n",
    "    else:\n",
    "        cropped_rotated = cv2.getRectSubPix(cropped, (int(factor * width), int(factor * height)), (size[0]/2, size[1]/2))\n",
    "\n",
    "    return cropped_rotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bdb07e9-94dd-42a8-8f38-a6896073142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cnts(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.blur(gray_img, (3,3))\n",
    "    \n",
    "    sigma = 0.33\n",
    "    v = np.median(blurred)\n",
    "    \n",
    "    #---- apply automatic Canny edge detection using the computed median----\n",
    "    lower = int(max(0, (1.0 - sigma) * v))    #---- lower threshold\n",
    "    upper = int(min(255, (1.0 + sigma) * v))  #---- upper threshold\n",
    "    thresh_img = cv2.Canny(blurred, lower, upper)\n",
    "    cnts, _ = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return cnts, gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa03abfc-da0e-4240-b86c-d92eb6c8948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cnts(cnts, gray_img):\n",
    "    filtered_list = []\n",
    "    pos_filtered_to_pos_source = {}\n",
    "    pos_filtered = 0\n",
    "    center_list = []\n",
    "    too_close = False\n",
    "    for pos_source, con in enumerate(cnts):\n",
    "        min_rect = cv2.minAreaRect(con)\n",
    "        center, size, angle = min_rect\n",
    "        area = size[0] * size[1]\n",
    "\n",
    "        if area < AREA_BORDER:\n",
    "            continue\n",
    "    \n",
    "        low_value = min(size[0], size[1])\n",
    "        high_value = max(size[0], size[1])\n",
    "        width_to_height = low_value / high_value\n",
    "    \n",
    "        if MIN_WIDTH_TO_HEIGHT < width_to_height < MAX_WIDTH_TO_HEIGHT:\n",
    "            for c_point in center_list:\n",
    "                too_close = np.all(np.isclose(center, c_point, rtol=0, atol=20))\n",
    "                if too_close:\n",
    "                    break\n",
    "    \n",
    "            if too_close:\n",
    "                continue\n",
    "            center_list.append(center)\n",
    "            cropped_img = rotate_and_crop(gray_img, min_rect)            \n",
    "            small_img = cv2.resize(cropped_img, COMPARED_SIZE)\n",
    "            filtered_list.append(small_img)\n",
    "            pos_filtered_to_pos_source[pos_filtered] = pos_source\n",
    "            pos_filtered += 1\n",
    "    \n",
    "    filtered_list = np.array(filtered_list)   \n",
    "    return filtered_list, pos_filtered_to_pos_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c21c0e6-0e79-4c1e-acdb-4f8cc650de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_cnts(prediction, pos_filtered_to_pos_source, cnts):\n",
    "    positive_contours = []\n",
    "    negative_contours = []\n",
    "    \n",
    "    for pos, value in enumerate(prediction):\n",
    "        idx = pos_filtered_to_pos_source[pos]\n",
    "        if value[0] >= 0.5:\n",
    "            positive_contours.append(cnts[idx])\n",
    "        else:\n",
    "            negative_contours.append(cnts[idx])\n",
    "\n",
    "    return positive_contours, negative_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab30145-4bb4-4cb3-aac1-cc79e88744b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_pts_first_cnt(positive_contours):\n",
    "    M = cv2.moments(positive_contours[0])\n",
    "    if (M[\"m00\"] != 0):\n",
    "        x_c = int(M[\"m10\"] / M[\"m00\"])\n",
    "        y_c = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        x_c = -1\n",
    "        y_c = -1\n",
    "    retval = cv2.arcLength(positive_contours[0], True)\n",
    "    points = cv2.approxPolyDP(positive_contours[0], 0.04 * retval, True)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c6ec620-531d-44f3-834e-86d82528af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_points(points, MAX_MERGE_DIST = 4):\n",
    "    to_merge = []\n",
    "    checked_points_idx = []\n",
    "    last_to_merge = False\n",
    "    for idx in range(len(points)-1):\n",
    "        first_point = points[idx, 0]\n",
    "        if idx not in checked_points_idx:\n",
    "            to_merge_bundle = [first_point]\n",
    "            \n",
    "            for idx2 in range(idx+1, len(points)):\n",
    "                second_point = points[idx2, 0]\n",
    "                dist = np.abs(first_point - second_point)\n",
    "                \n",
    "                if dist[0] < MAX_MERGE_DIST and dist[1] < MAX_MERGE_DIST:\n",
    "                    to_merge_bundle.append(second_point)\n",
    "                    checked_points_idx.append(idx2)\n",
    "                    if idx2 == len(points)-1:\n",
    "                        last_to_merge = True\n",
    "    \n",
    "            to_merge.append(to_merge_bundle)\n",
    "    \n",
    "    if not last_to_merge:\n",
    "        to_merge.append([points[-1, 0]])\n",
    "\n",
    "    filtered_points = []\n",
    "    for to_merge_bundle in to_merge:\n",
    "        if len(to_merge_bundle) == 1:\n",
    "            filtered_points.append(to_merge_bundle[0])\n",
    "        else:\n",
    "            filtered_point = np.sum(to_merge_bundle, axis=0)/ len(to_merge_bundle)\n",
    "            filtered_points.append(filtered_point)\n",
    "\n",
    "    return filtered_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f743d4cc-df01-4b21-b0a5-0b785b3d780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rot_and_trans(H, K):\n",
    "    H = H.T\n",
    "    h1 = H[0]\n",
    "    h2 = H[1]\n",
    "    h3 = H[2]\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    L = 1 / np.linalg.norm(np.dot(K_inv, h1))\n",
    "    r1 = L * np.dot(K_inv, h1)\n",
    "    r2 = L * np.dot(K_inv, h2)\n",
    "    r3 = np.cross(r1, r2)\n",
    "    \n",
    "    T = L * np.dot(K_inv, h3)\n",
    "    \n",
    "    R = np.array([[r1], [r2], [r3]])\n",
    "    R = np.reshape(R, (3, 3))\n",
    "    U, S, V = np.linalg.svd(R, full_matrices=True)\n",
    "    U = np.matrix(U)\n",
    "    V = np.matrix(V)\n",
    "    R = U * V\n",
    "    \n",
    "    alpha = np.rad2deg(np.arctan2(R[2, 1], R[2, 2]))\n",
    "    beta = np.rad2deg(np.arctan2(-R[2, 0], np.sqrt(R[2, 1] * R[2, 1] + R[2, 2] * R[2, 2])))\n",
    "    gamma = np.rad2deg(np.arctan2(R[1, 0], R[0, 0]))\n",
    "    return (np.array((alpha, beta, gamma)), T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6dda6a9-bdb2-4ca9-9ecd-67b1bf24f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_pos_in_img(img, model):\n",
    "    if img is None:\n",
    "        raise IOError('file not valid')\n",
    "    \n",
    "    cnts, gray_img = extract_cnts(img)\n",
    "    filtered_list, pos_filtered_to_pos_source = filter_cnts(cnts, gray_img)\n",
    "\n",
    "    if not len(filtered_list):\n",
    "        return None, None, None, None\n",
    "    \n",
    "    prediction = model.predict(filtered_list, verbose=0)\n",
    "    pos_cnts, neg_cnts = sort_cnts(prediction, pos_filtered_to_pos_source, cnts)\n",
    "\n",
    "    if not len(pos_cnts):\n",
    "        return None, None, pos_cnts, neg_cnts\n",
    "        \n",
    "    img_points = extract_feature_pts_first_cnt(pos_cnts)\n",
    "    img_points = merge_points(img_points)\n",
    "    if len(img_points) != 5:\n",
    "        return None, None, pos_cnts, neg_cnts\n",
    "        \n",
    "    img_points = np.reshape(img_points, (5,2))\n",
    "    img_points = img_points[np.lexsort((img_points[:,1], img_points[:,0]))]\n",
    "    \n",
    "    H, mask = cv2.findHomography(points_printed, img_points, cv2.RANSAC)\n",
    "    R, T = calc_rot_and_trans(H, K)\n",
    "    return R, T, pos_cnts, neg_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ca5d70c-f9f3-4ae8-96b4-2d469ae7b1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 23:35:14.191961: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "if not 'model' in dir():\n",
    "    print('load model...')\n",
    "    from keras.models import load_model\n",
    "    model = load_model('arrow_detection.keras')\n",
    "    print('loaded model')\n",
    "    \n",
    "else:\n",
    "    print('model already loaded')\n",
    "    \n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9239da82-9244-4366-8103-ae20eff1d1a2",
   "metadata": {},
   "source": [
    "## Camera test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ec76569-5f8f-4321-80d6-61a92eaed7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_nbr = 2\n",
    "# np.set_printoptions(precision=3)\n",
    "WIDTH = 640\n",
    "HEIGHT = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "784827a9-f13a-4cfd-a8c7-1131f484b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aborting\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# bufferless VideoCapture\n",
    "class VideoCapture:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.image = None\n",
    "        self.stopped = False\n",
    "        self.Q = Queue(maxsize=2)\n",
    "        self.cap = cv2.VideoCapture(*args, **kwargs)\n",
    "        self.lock = threading.Lock()\n",
    "        self.event = threading.Event()\n",
    "        self.t = threading.Thread(target=self._reader)\n",
    "        self.t.start()\n",
    "\n",
    "    def _reader(self):\n",
    "        while not self.event.is_set():\n",
    "            with self.lock:\n",
    "                if self.Q.full():\n",
    "                    _ = self.Q.get()  # remove value for new ones\n",
    "                    \n",
    "                ret, image = self.cap.read()\n",
    "                if not ret:\n",
    "                    self.cap.release()\n",
    "                    raise ValueError('could not get image from VideoCapture')\n",
    "                    \n",
    "                self.Q.put(image)\n",
    "\n",
    "    def read(self):\n",
    "        return True, self.Q.get()\n",
    "\n",
    "    def isOpened(self):\n",
    "        return self.cap.isOpened()\n",
    "\n",
    "    def set(self, *args):\n",
    "        with self.lock:\n",
    "            self.cap.set(*args)\n",
    "\n",
    "    def release(self):\n",
    "        self.event.set()\n",
    "        self.t.join()\n",
    "        self.cap.release()\n",
    "\n",
    "\n",
    "cap = VideoCapture(cam_nbr)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    cap.release()\n",
    "    raise SystemExit(f'could not open camera at index {cam_nbr}')\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "\n",
    "abort = False\n",
    "y_location = HEIGHT-10\n",
    "time_start = time()\n",
    "text = ''\n",
    "pos_cnts = ()\n",
    "neg_cnts = ()\n",
    "\n",
    "while not abort:\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    time_now = time()\n",
    "    if (time_now - time_start) >1:\n",
    "        time_start = time_now\n",
    "        try:\n",
    "            R, T, tmp0, tmp1 = est_pos_in_img(img, model)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            break\n",
    "\n",
    "        if tmp0 is not None:\n",
    "            pos_cnts = tmp0\n",
    "            neg_cnts = tmp1\n",
    "            \n",
    "        if R is not None: # T is not None, too\n",
    "            text = f'R:{np.array2string(R, precision=3, floatmode='fixed')}; T:{np.array2string(T, precision=3, floatmode='fixed')}'\n",
    "    \n",
    "    cv2.drawContours(img, pos_cnts, -1, (255,0,0), 2)\n",
    "    cv2.drawContours(img, neg_cnts, -1, (0,0,255), 2)\n",
    "    cv2.putText(img, text, (10, y_location), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 0))        \n",
    "    cv2.imshow('camera test', img)\n",
    "    key = cv2.waitKey(25) & 0xFF\n",
    "    if key == 27 or key == 113:\n",
    "        print('aborting')\n",
    "        abort = True\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aeaa6a7-b011-4280-a9c6-9b9f9008d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83c303-965f-434e-a476-520f69511ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
